{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# |Modeling| Walk Forward Validation with Tree-based models\n",
    "## Forecasting Cross Validation pipeline with Tree-based Scikit-learn models\n",
    "\n",
    "**Objetivo**: The primary objective of this notebook is to perform experimentation with the tree-based models for multi-step ahead forecasting.\n",
    "\n",
    "**Conclusions**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.insert(0,'../..')\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import warnings\n",
    "from typing import Any\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import logging\n",
    "from joblib import load, dump\n",
    "from scipy.stats import uniform, randint, norm\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# from src.models.evaluate_model import walk_forward_validation, model_crossval_pipeline\n",
    "# from src.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../src/configuration/project_config.yaml\", 'r') as f:\n",
    "    config = yaml.safe_load(f.read())\n",
    "    model_config = config['model_config']\n",
    "    data_config = config['data_config']\n",
    "    PROCESSED_DATA_PATH = data_config['paths']['processed_data_path']\n",
    "    PROCESSED_DATA_NAME = data_config['table_names']['processed_table_name']\n",
    "    OUTPUT_DATA_PATH = data_config['paths']['output_data_path']\n",
    "    OUTPUT_DATA_NAME = data_config['table_names']['output_table_name']\n",
    "    DAILY_PERFORMANCE_DATA_NAME = data_config['table_names']['model_performance_table_name']\n",
    "    CROSS_VAL_DATA_NAME = data_config['table_names']['cross_validation_table_name']\n",
    "    MODELS_PATH = data_config['paths']['models_path']\n",
    "    TARGET_COL = model_config['target_col']\n",
    "    CATEGORY_COL = model_config['category_col']\n",
    "    PREDICTED_COL = model_config['predicted_col']\n",
    "    FORECAST_HORIZON = model_config['forecast_horizon']\n",
    "    features_list = config['features_list']\n",
    "    available_models = model_config['available_models']\n",
    "\n",
    "with open(\"../../src/configuration/logging_config.yaml\", 'r') as f:  \n",
    "    logging_config = yaml.safe_load(f.read())\n",
    "    logging.config.dictConfig(logging_config)\n",
    "    logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "    logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_test_values(X: pd.DataFrame, y: pd.Series, day: int) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Prepares the feature and target data for testing on a specific day.\n",
    "\n",
    "    This function extracts a single row (or the remaining rows if it's the last day) \n",
    "    from the input feature DataFrame (X) and target Series (y) to create a test set for \n",
    "    a specific day. The day is specified relative to the end of the DataFrame, where\n",
    "    day 1 represents the last day, day 2 the second-to-last day, and so on.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The feature DataFrame containing all historical data.\n",
    "        y (pd.Series): The target Series containing all historical target values.\n",
    "        day (int): The day to extract for testing, relative to the end of the DataFrames.\n",
    "                   1 is the last day, 2 is the second-to-last, etc.\n",
    "\n",
    "    Returns:\n",
    "        tuple[pd.DataFrame, pd.Series]: A tuple containing:\n",
    "            - X_test (pd.DataFrame): A DataFrame with the features for the specified day.\n",
    "            - y_test (pd.Series): A Series with the target value for the specified day.\n",
    "\n",
    "    Raises:\n",
    "        IndexError: If the specified `day` is out of bounds for the input DataFrames.\n",
    "    \"\"\"\n",
    "    if day != 1:\n",
    "        # Select a single row using negative indexing\n",
    "        X_test = X.iloc[-day:-day+1,:]\n",
    "        y_test = y.iloc[-day:-day+1]\n",
    "\n",
    "    else:\n",
    "        # Handle the special case of the last day (day 1)\n",
    "        X_test = X.iloc[-day:,:]\n",
    "        y_test = y.iloc[-day:]\n",
    "\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return X_test, y_test\n",
    "\n",
    "\n",
    "def calculate_metrics(pred_df, actuals, predictions):\n",
    "    logger.debug(\"Calculating the evaluation metrics...\")\n",
    "    \n",
    "    model_mape = round(mean_absolute_percentage_error(actuals, predictions), 4)\n",
    "    model_rmse = round(np.sqrt(mean_squared_error(actuals, predictions)), 2)\n",
    "    model_mae = round(mean_absolute_error(actuals, predictions), 2)\n",
    "    model_wape = round((pred_df.ACTUAL - pred_df.FORECAST).abs().sum() / pred_df.ACTUAL.sum(), 2)\n",
    "\n",
    "    pred_df[\"MAPE\"] = model_mape\n",
    "    pred_df[\"MAE\"] = model_mae\n",
    "    pred_df[\"WAPE\"] = model_wape\n",
    "    pred_df[\"RMSE\"] = model_rmse\n",
    "\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def stepwise_validation(X: pd.DataFrame, y: pd.Series, forecast_horizon: int, model_type: Any, ticker: str, tune_params: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs iterativly 1 step ahead forecast validation for a given model type and ticker symbol.\n",
    "\n",
    "    This function iteratively trains a model on historical data, then forecasts into the future using a sliding window approach.\n",
    "    The forecast horizon is adjusted to exclude weekends. It returns a DataFrame with the actual and predicted values, along with performance metrics.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Feature matrix.\n",
    "        y (pd.Series): Target variable.\n",
    "        forecast_horizon (int): The number of days to forecast ahead.\n",
    "        model_type (Any): The type of model to use (e.g., 'xgb', 'rf', 'et').\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        tune_params (bool, optional): Whether to perform hyperparameter tuning. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing:\n",
    "            - DATE: The dates of the predictions.\n",
    "            - ACTUAL: The actual target values.\n",
    "            - PREDICTED_COL: The predicted values.\n",
    "            - MODEL_TYPE: The type of model used.\n",
    "            - CLASS: \"Testing\" (indicates the type of data).\n",
    "            - Additional columns with performance metrics (MAE, RMSE, MAPE).\n",
    "    \"\"\"\n",
    "\n",
    "    # Create empty list for storing each prediction\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    dates = []\n",
    "    X_testing_df = pd.DataFrame()\n",
    "\n",
    "    forecast_horizon = weekend_adj_forecast_horizon(forecast_horizon, 2)\n",
    "    \n",
    "    # get the one-shot training set\n",
    "    X_train = X.iloc[:-forecast_horizon, :]\n",
    "    y_train = y.iloc[:-forecast_horizon]\n",
    "    final_y = y_train.copy()\n",
    "\n",
    "    logger.debug(f\"Last training date: {X_train[\"DATE\"].max().date()}\")\n",
    "\n",
    "    best_model = train_model(\n",
    "        X_train.drop(columns=[\"DATE\"]),\n",
    "        y_train,\n",
    "        model_type,\n",
    "        ticker,\n",
    "        tune_params,\n",
    "        save_model=False\n",
    "    )\n",
    "\n",
    "    for day in range(forecast_horizon, 0, -1):\n",
    "        X_test, y_test = update_test_values(X, y, day)\n",
    "        logger.debug(f\"Testing Date: {X_test[\"DATE\"].min().date()}\")\n",
    "\n",
    "        if len(predictions) != 0:\n",
    "\n",
    "            X_test = update_lag_features(X_test, -1, list(final_y.values), X_test.columns)\n",
    "            X_test = update_ma_features(X_test, -1, list(final_y.values), X_test.columns)\n",
    "\n",
    "        prediction = best_model.predict(X_test.drop(\"DATE\", axis=1))\n",
    "\n",
    "        # store the results\n",
    "        predictions.append(prediction[0])\n",
    "        actuals.append(y_test.values[0])\n",
    "        dates.append(X_test[\"DATE\"].max())\n",
    "\n",
    "        final_y = pd.concat([final_y, pd.Series(prediction[0])], axis=0)\n",
    "        final_y = final_y.reset_index(drop=True)\n",
    "        X_testing_df = pd.concat([X_testing_df, X_test], axis=0)\n",
    "\n",
    "    pred_df = pd.DataFrame(list(zip(dates, actuals, predictions)), columns=[\"DATE\", \"ACTUAL\", PREDICTED_COL])\n",
    "    pred_df = calculate_metrics(pred_df, actuals, predictions)\n",
    "    pred_df[\"MODEL_TYPE\"] = str(type(best_model)).split('.')[-1][:-2]\n",
    "    pred_df[\"CLASS\"] = \"Testing\"\n",
    "    \n",
    "    X_testing_df[PREDICTED_COL] = predictions\n",
    "    X_testing_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Plotting the Validation Results\n",
    "    # validation_metrics_fig = visualize_validation_results(pred_df, model_mape, model_mae, model_wape, ticker)\n",
    "\n",
    "    # Plotting the Learning Results\n",
    "    #learning_curves_fig, feat_imp = extract_learning_curves(best_model, display=True)\n",
    "    \n",
    "    return pred_df, X_testing_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_crossval_pipeline(tune_params, model_type, ticker):\n",
    "    available_models = model_config['available_models']\n",
    "    validation_report_df = pd.DataFrame()\n",
    "\n",
    "    logger.debug(\"Loading the featurized dataset..\")\n",
    "    feature_df = pd.read_csv(os.path.join('../../'+PROCESSED_DATA_PATH, PROCESSED_DATA_NAME), parse_dates=[\"DATE\"])\n",
    "\n",
    "    # Check the ticker parameter\n",
    "    if ticker:\n",
    "        ticker = ticker.upper() + '.SA'\n",
    "        feature_df = feature_df[feature_df[CATEGORY_COL] == ticker]\n",
    "        \n",
    "    # Check the model_type parameter \n",
    "    if model_type is not None and model_type not in available_models:\n",
    "        raise ValueError(f\"Invalid model_type: {model_type}. Choose from: {available_models}\")\n",
    "    \n",
    "    elif model_type:\n",
    "        available_models = [model_type.upper()]\n",
    "\n",
    "    for ticker in feature_df[CATEGORY_COL].unique():\n",
    "        filtered_feature_df = feature_df[feature_df[CATEGORY_COL] == ticker].copy().drop(CATEGORY_COL, axis=1)\n",
    "        \n",
    "        for model_type in available_models:\n",
    "            logger.info(f\"Performing model cross validation for ticker symbol [{ticker}] using model [{model_type}]...\")\n",
    " \n",
    "            predictions_df, X_testing_df = stepwise_validation(\n",
    "                X=filtered_feature_df.drop(columns=[TARGET_COL], axis=1),\n",
    "                y=filtered_feature_df[TARGET_COL],\n",
    "                forecast_horizon=FORECAST_HORIZON,\n",
    "                model_type=model_type,\n",
    "                ticker=ticker,\n",
    "                tune_params=tune_params\n",
    "            )\n",
    "\n",
    "            predictions_df[CATEGORY_COL] = ticker\n",
    "            predictions_df[\"TRAINING_DATE\"] = dt.datetime.today().date()\n",
    "            validation_report_df = pd.concat([validation_report_df, predictions_df], axis=0)\n",
    "    \n",
    "    logger.info(\"Writing the testing results dataframe...\")\n",
    "    validation_report_df.to_csv(os.path.join(OUTPUT_DATA_PATH, CROSS_VAL_DATA_NAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-19 13:26:53,596 - __main__ - INFO - Performing model cross validation for ticker symbol [BOVA11.SA] using model [XGB]...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weekend_adj_forecast_horizon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_crossval_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mmodel_crossval_pipeline\u001b[0;34m(tune_params, model_type, ticker)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m available_models:\n\u001b[1;32m     24\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming model cross validation for ticker symbol [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] using model [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     predictions_df, X_testing_df \u001b[38;5;241m=\u001b[39m \u001b[43mstepwise_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_feature_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTARGET_COL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiltered_feature_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTARGET_COL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFORECAST_HORIZON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtune_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune_params\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     predictions_df[CATEGORY_COL] \u001b[38;5;241m=\u001b[39m ticker\n\u001b[1;32m     36\u001b[0m     predictions_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAINING_DATE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mdate()\n",
      "Cell \u001b[0;32mIn[6], line 86\u001b[0m, in \u001b[0;36mstepwise_validation\u001b[0;34m(X, y, forecast_horizon, model_type, ticker, tune_params)\u001b[0m\n\u001b[1;32m     83\u001b[0m dates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     84\u001b[0m X_testing_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 86\u001b[0m forecast_horizon \u001b[38;5;241m=\u001b[39m \u001b[43mweekend_adj_forecast_horizon\u001b[49m(forecast_horizon, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# get the one-shot training set\u001b[39;00m\n\u001b[1;32m     89\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39mforecast_horizon, :]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weekend_adj_forecast_horizon' is not defined"
     ]
    }
   ],
   "source": [
    "model_crossval_pipeline(False, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-based-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
